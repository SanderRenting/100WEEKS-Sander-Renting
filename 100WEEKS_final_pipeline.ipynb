{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First upload central-tableau-export-2.0.csv"
      ],
      "metadata": {
        "id": "xRK18K1CF8C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run code"
      ],
      "metadata": {
        "id": "QPNaSMQQF38Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install io\n",
        "!pip install --upgrade pandas\n",
        "!pip install xlsxwriter"
        
      ],
      "metadata": {
        "id": "Tz1pZt7LGLco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 1: IMPORTS\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from io import BytesIO\n",
        "import xlsxwriter\n",
        "\n",
        "# Note: This script requires 'xlsxwriter' to be installed for saving multi-sheet Excel files.\n",
        "# You can install it via pip: pip install xlsxwriter\n",
        "\n",
        "# =============================================================================\n",
        "# PART 2: DATA LOADING AND PRE-PROCESSING\n",
        "# =============================================================================\n",
        "df = pd.read_csv('central-tableau-export-2.0.csv')\n",
        "\n",
        "\n",
        "countries = ['GHA', 'RWA', 'UGA', 'CIV', 'KEN']\n",
        "df = df[df['Country'].isin(countries)]\n",
        "\n",
        "df = df[~df['Round'].isin(['Onboarding', '6', '6.0']) & df['Round'].notna()]\n",
        "df['Round'] = pd.to_numeric(df['Round'], errors='coerce').dropna()\n",
        "df = df[df['Round'] % 1 == 0]\n",
        "df['Round'] = df['Round'].astype(int)\n",
        "df = df[df['Round'].isin([0, 1, 2, 3, 100, 102])]\n",
        "df['Round'] = df['Round'].astype(str)\n",
        "df = df.sort_values(by=['Country', 'Groupnr', 'Round'])\n",
        "\n",
        "print(\"Initial 'Round' values found:\", df['Round'].unique())\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3: VARIABLE DEFINITIONS & INITIAL MAPPING\n",
        "# =============================================================================\n",
        "all_columns = [\n",
        "    \"Groupnr\", \"Round\", \"Country\", \"childmortality\", \"childmortalitytime\", *[f\"foodsecurity{i}\" for i in range(1, 10)],\n",
        "    *[f\"foodsecurity{i}freq\" for i in range(1, 10)],\n",
        "    \"fuelcooking\", \"sourcelighting\", \"watersource\", \"timewatersource_1\", \"timewatersourceunit\", \"Toiletfacility\",\n",
        "    \"materialroof\", \"materialfloor\", \"materialwallsext\",\n",
        "    \"assetsmatrix2_7\", \"assetsmatrix2_14\", \"assetsmatrix2_16\", \"assetsmatrix1_23\", \"assetsmatrix3_14\",\n",
        "    \"assetsmatrix3_16\", \"assetsmatrix2_12\", \"assetsmatrix3_22\",\n",
        "    *[f\"HHMschool_{n}\" for n in range(1, 6)], *[f\"HHMschoolnow_{n}\" for n in range(1, 6)],\n",
        "    *[f\"HHMschoolcompl_{n}\" for n in range(1, 6)], *[f\"HHMage_1_{n}\" for n in range(1, 21)], \"school\", \"schoolcompleted\",\n",
        "    \"savinghowmuch_1\", \"savinghowmuch_2\", \"savinghowmuch_3\", \"savingstotal_1\", \"debt\", \"debtamount_1\", \"debtnote\",\n",
        "    *[f\"anxiety{i}\" for i in range(1, 8)],\n",
        "    \"psychwellbeing_1\", \"psychwellbeing_3\", \"psychwellbeing_5\", \"psychwellbeing2_5\", \"jealousy\", \"jealousywhat\",\n",
        "    *[f\"livestocknumbers_{i}\" for i in [1, 13, 3, 4, 5, 6, 11, 8, 9, 7, 2, 10]], \"assetsmatrix1_4\", \"assetsmatrix1_5\",\n",
        "    \"assetsmatrix1_22\", \"assetsmatrix2_7\", \"assetsmatrix2_14\",\n",
        "    \"assetsmatrix2_15\", \"assetsmatrix2_16\", \"assetsmatrix2_8\", \"assetsmatrix3_17\", \"assetsmatrix2_17\",\n",
        "    \"assetsmatrix2_18\", \"assetsmatrix2_19\", \"assetsmatrix2_11\",\n",
        "    \"assetsmatrix2_12\", \"assetsmatrix3_14\", \"assetsmatrix1_23\", \"assetsmatrix3_15\", \"assetsmatrix3_16\",\n",
        "    \"assetsmatrix3_22\", \"assetsmatrix3_23\", \"occupationmain\",\n",
        "    \"ownsland_scto\", \"meetings1\", \"moneywithdraw\", \"moneyproblems\"\n",
        "]\n",
        "\n",
        "columns_available = [col for col in all_columns if col in df.columns]\n",
        "df = df[columns_available]\n",
        "\n",
        "def livestock_normal(val):\n",
        "    if pd.isna(val) or val == 0: return 0\n",
        "    val = int(val)\n",
        "    if val in [1, 2, 3, 4, 5]: return str(val)\n",
        "    elif 6 <= val <= 10: return '6-10'\n",
        "    elif 11 <= val <= 20: return '11-20'\n",
        "    elif val > 20: return '20+'\n",
        "livestock_indices_normal = [1, 13, 3, 4, 8, 9, 7, 2, 10]\n",
        "for i in livestock_indices_normal:\n",
        "    col = f'livestocknumbers_{i}'\n",
        "    if col in df.columns: df[col] = df[col].apply(livestock_normal)\n",
        "\n",
        "def livestock_high(val):\n",
        "    if pd.isna(val) or val == 0: return 0\n",
        "    val = int(val)\n",
        "    if val in [1, 2, 3, 4, 5]: return str(val)\n",
        "    elif 6 <= val <= 10: return '6-10'\n",
        "    elif 11 <= val <= 20: return '11-20'\n",
        "    elif 21 <= val <= 50: return '21-50'\n",
        "    elif val >= 51: return '51+'\n",
        "    else: return 0\n",
        "\n",
        "livestock_indices_high = [5,6,11]\n",
        "for i in livestock_indices_high:\n",
        "    col = f'livestocknumbers_{i}'\n",
        "    if col in df.columns: df[col] = df[col].apply(livestock_high)\n",
        "\n",
        "def mpi_water(row):\n",
        "    if row['timewatersource_1'] > 30: return 1.0\n",
        "    water = row['watersource']\n",
        "    if water in [1, 2, 5, 7, 12]: return 0.0\n",
        "    elif water in [4, 10]: return 0.3\n",
        "    elif water in [3, 6]: return 0.6\n",
        "    elif water in [8, 9, 11]: return 1.0\n",
        "    else: return None\n",
        "if 'timewatersource_1' in df.columns and 'watersource' in df.columns:\n",
        "    df['MPI_water'] = df.apply(mpi_water, axis=1)\n",
        "\n",
        "def MPI_fuel(row):\n",
        "    fuel = row['fuelcooking']\n",
        "    if fuel in [3, 4, 5, 6]: return 0.0\n",
        "    elif fuel in [7]: return 0.3\n",
        "    elif fuel in [2, 10]: return 0.6\n",
        "    elif fuel in [1, 8, 9]: return 1.0\n",
        "    else: return None\n",
        "if 'fuelcooking' in df.columns:\n",
        "    df['MPI_fuel'] = df.apply(MPI_fuel, axis=1)\n",
        "\n",
        "def MPI_electricity(row):\n",
        "    source = row['sourcelighting']\n",
        "    if source in [1, 2, 4, 9, 15]: return 0.0\n",
        "    elif source in [3]: return 0.3\n",
        "    elif source in [5, 7, 8, 10, 13, 14]: return 0.6\n",
        "    elif source in [6, 11, 12]: return 1.0\n",
        "    else: return None\n",
        "if 'sourcelighting' in df.columns:\n",
        "    df['MPI_electricity'] = df.apply(MPI_electricity, axis=1)\n",
        "\n",
        "def MPI_sanitation(row):\n",
        "    toiletfacility = row['Toiletfacility']\n",
        "    if toiletfacility in [1]: return 2\n",
        "    elif toiletfacility in [6]: return 0.2\n",
        "    elif toiletfacility in [5]: return 0.6\n",
        "    elif toiletfacility in [3]: return 1.0\n",
        "    else: return None\n",
        "if 'Toiletfacility' in df.columns:\n",
        "    df['MPI_sanitation'] = df.apply(MPI_sanitation, axis=1)\n",
        "\n",
        "def MPI_floor(row):\n",
        "    material = row['materialfloor']\n",
        "    if material in [5, 6, 4, 9]: return 2\n",
        "    elif material in [3, 8]: return 1\n",
        "    elif material in [1, 2]: return 0\n",
        "    else: return None\n",
        "\n",
        "def MPI_roof(row):\n",
        "    material = row['materialroof']\n",
        "    if material in [4, 2, 3, 8]: return 2\n",
        "    elif material in [5, 7]: return 1\n",
        "    elif material in [1, 9]: return 0\n",
        "    else: return None\n",
        "\n",
        "def MPI_wall(row):\n",
        "    material = row['materialwallsext']\n",
        "    if material in [4, 6, 2, 3, 13]: return 2\n",
        "    elif material in [1, 5, 8, 9, 11]: return 1\n",
        "    elif material in [7, 14]: return 0\n",
        "    else: return None\n",
        "\n",
        "if 'materialwallsext' in df.columns: df['material_walls'] = df.apply(MPI_wall, axis=1)\n",
        "if 'materialfloor' in df.columns: df['material_floor'] = df.apply(MPI_floor, axis=1)\n",
        "if 'materialroof' in df.columns: df['material_roof'] = df.apply(MPI_roof, axis=1)\n",
        "\n",
        "def average_material_score(row):\n",
        "    values = [row.get('material_walls'), row.get('material_floor'), row.get('material_roof')]\n",
        "    valid_values = [v for v in values if v is not None]\n",
        "    return sum(valid_values) / len(valid_values) if valid_values else None\n",
        "df['MPI_house'] = df.apply(average_material_score, axis=1)\n",
        "\n",
        "def update_debtamount(row):\n",
        "    if row['debt'] == 2.0: return 0\n",
        "    elif row['debt'] == 1.0: return row['debtamount_1']\n",
        "    else: return None\n",
        "if 'debt' in df.columns and 'debtamount_1' in df.columns:\n",
        "    df['debtamount_1'] = df.apply(update_debtamount, axis=1)\n",
        "\n",
        "def calculate_school(row, n):\n",
        "    age_col = f'HHMage_1_{n}'\n",
        "    school_col = f'HHMschool_{n}'\n",
        "    schoolcompl_col = f'HHMschoolcompl_{n}'\n",
        "    if pd.isnull(row.get(age_col)) or row.get(age_col) < 10 or pd.isnull(row.get(school_col)): return None\n",
        "    elif row.get(school_col) == 2: return 1\n",
        "    elif pd.isnull(row.get(schoolcompl_col)): return 1\n",
        "    elif row.get(schoolcompl_col) in [1, -88]: return 1\n",
        "    else: return 0\n",
        "for n in range(1, 21):\n",
        "    if f'HHMage_1_{n}' in df.columns and f'HHMschool_{n}' in df.columns and f'HHMschoolcompl_{n}' in df.columns:\n",
        "      df[f'MPI_6yearsofschool_perHHM_{n}'] = df.apply(lambda row: calculate_school(row, n), axis=1)\n",
        "\n",
        "def MPI_6yearsofschool_woman(row):\n",
        "    if pd.isnull(row.get('school')): return None\n",
        "    elif row.get('school') == 2: return 1\n",
        "    elif pd.isnull(row.get('schoolcompleted')): return 1\n",
        "    elif row.get('schoolcompleted') in [1, -88]: return 1\n",
        "    else: return 0\n",
        "if 'school' in df.columns and 'schoolcompleted' in df.columns:\n",
        "    df['MPI_6yearsofschool_woman'] = df.apply(MPI_6yearsofschool_woman, axis=1)\n",
        "\n",
        "def MPI_6yearsofschool_allHHM(row):\n",
        "    education_columns = [col for col in [f'MPI_6yearsofschool_perHHM_{i}' for i in range(1, 21)] + ['MPI_6yearsofschool_woman'] if col in row.index]\n",
        "    if not education_columns or all(pd.isnull(row[col]) for col in education_columns): return None\n",
        "    elif any(row[col] == 0 for col in education_columns): return 0\n",
        "    else: return 1\n",
        "df['MPI_6yearsofschool_allHHM'] = df.apply(MPI_6yearsofschool_allHHM, axis=1)\n",
        "\n",
        "if 'occupationmain' in df.columns:\n",
        "    occupation_scores = {0: 0, 6: 0, 4: 0, 31: 0, 16: 0, 18: 1, 54: 1, 20: 1, 8: 1, 36: 1, 56: 1, 39: 1, 48: 1, 7: 1, 5: 1, 47: 1, 17: 1, 50: 1, 40: 1, 15: 2, 37: 2, 55: 2, 57: 2, 58: 2, 52: 2, 49: 2}\n",
        "    df['occupation_score'] = df['occupationmain'].map(occupation_scores)\n",
        "\n",
        "# =============================================================================\n",
        "# === THIS IS THE CORRECTED FUNCTION ===\n",
        "# =============================================================================\n",
        "def map_school_level_to_score(value):\n",
        "    # Convert value to numeric. If it can't be converted, it becomes NaN.\n",
        "    value = pd.to_numeric(value, errors='coerce')\n",
        "\n",
        "    # The rest of the logic now works safely because `value` is either a number or NaN.\n",
        "    if pd.isnull(value) or value in [-88, 1, 2]:\n",
        "        return 0  # bad\n",
        "    elif value in [3, 4]:\n",
        "        return 1  # medium\n",
        "    elif value >= 5:\n",
        "        return 2  # good\n",
        "    else:\n",
        "        return 0  # fallback for other numbers or cases\n",
        "\n",
        "school_columns = [f\"HHMschoolcompl_{n}\" for n in range(1, 6)] + [\"schoolcompleted\"]\n",
        "for col in school_columns:\n",
        "    if col in df.columns:\n",
        "        df[f\"{col}_score\"] = df[col].apply(map_school_level_to_score)\n",
        "\n",
        "if 'jealousywhat' in df.columns:\n",
        "    def map_jealousy_score(code):\n",
        "        if code in [3, 4, 5, 6, 7]: return 0\n",
        "        elif code in [1, 2, 8]: return 1\n",
        "        elif code == 0: return 2\n",
        "        else: return None\n",
        "    df['jealousywhat_score'] = df['jealousywhat'].apply(map_jealousy_score)\n",
        "\n",
        "# =============================================================================\n",
        "# PART 4: MAP REMAINING & BINARY VARIABLES\n",
        "# =============================================================================\n",
        "print(\"\\nMapping remaining categorical variables to 0, 1, 2 scores...\")\n",
        "\n",
        "livestock_score_map = {0: 0, '1': 1, '2': 1, '3': 1, '4': 1, '5': 1, '6-10': 2, '11-20': 2, '20+': 2, '21-50': 2, '51+': 2}\n",
        "livestock_cols = [f\"livestocknumbers_{i}\" for i in [1, 13, 3, 4, 5, 6, 11, 8, 9, 7, 2, 10]]\n",
        "for col in livestock_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map(livestock_score_map)\n",
        "\n",
        "if 'debtnote' in df.columns:\n",
        "    debt_reason_map = {1: 0, 2: 0, 4: 0, 7: 0, 9: 0, 3: 1, 5: 1, 6: 2, 8: 2}\n",
        "    df['debtnote_score'] = df['debtnote'].map(debt_reason_map)\n",
        "\n",
        "print(\"\\nMapping binary variables to a 0 (bad) / 1 (good) scale...\")\n",
        "binary_neg = [\n",
        "    \"debt\", \"foodsecurity1\",\"foodsecurity2\", \"foodsecurity3\", \"foodsecurity4\", \"foodsecurity5\",\n",
        "    \"foodsecurity6\", \"foodsecurity7\", \"foodsecurity8\", \"foodsecurity9\", \"childmortality\",\n",
        "    \"jealousy\", \"assetsmatrix1_4\", \"assetsmatrix1_5\", \"assetsmatrix1_22\", \"assetsmatrix2_15\",\n",
        "    \"assetsmatrix2_8\", \"assetsmatrix3_17\", \"assetsmatrix2_17\",\n",
        "    \"assetsmatrix2_18\", \"assetsmatrix2_19\", \"assetsmatrix2_11\",\n",
        "    \"assetsmatrix3_15\", \"assetsmatrix3_23\"\n",
        "]\n",
        "\n",
        "binary_pos = [\n",
        "    \"HHMschoolnow_1\", \"HHMschoolnow_2\", \"HHMschoolnow_3\",\n",
        "    \"HHMschoolnow_4\", \"HHMschoolnow_5\",\n",
        "    \"school\", \"meetings1\", \"moneywithdraw\", \"moneyproblems\"\n",
        "]\n",
        "\n",
        "neg_map = {1.0: 0.0, 2.0: 1.0}\n",
        "for col in binary_neg:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df[col] = df[col].map(neg_map)\n",
        "        print(f\"Mapped '{col}' (negative binary) to 0/1.\")\n",
        "\n",
        "pos_map = {1.0: 1.0, 2.0: 0.0}\n",
        "for col in binary_pos:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df[col] = df[col].map(pos_map)\n",
        "        print(f\"Mapped '{col}' (positive binary) to 0/1.\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 5: SAVE TO EXCEL\n",
        "# =============================================================================\n",
        "output_filename = 'processed_data_with_scores.xlsx'\n",
        "print(f\"\\nSaving the processed DataFrame to '{output_filename}'...\")\n",
        "\n",
        "try:\n",
        "    with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:\n",
        "        df.to_excel(writer, sheet_name='Processed_Data', index=False)\n",
        "    print(\"File saved successfully.\")\n",
        "except ImportError:\n",
        "    print(\"Warning: 'xlsxwriter' is not installed. Trying with default engine.\")\n",
        "    try:\n",
        "        df.to_excel(output_filename, index=False)\n",
        "        print(\"File saved successfully with default engine.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving the file: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the file: {e}\")"
      ],
      "metadata": {
        "id": "IVgQ6YiDQa43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Variable Definitions ---\n",
        "numerical = [\n",
        "    \"savinghowmuch_1\", \"savinghowmuch_2\", \"savinghowmuch_3\",\n",
        "    \"savingstotal_1\", \"debtamount_1\", \"timewatersource_1\"\n",
        "]\n",
        "ordered_categorical = [\n",
        "    *[f\"foodsecurity{i}freq\" for i in range(1, 10)],\n",
        "    *[f\"anxiety{i}\" for i in range(1, 8)],\n",
        "    \"psychwellbeing_1\", \"psychwellbeing_3\", \"psychwellbeing_5\", \"psychwellbeing2_5\"\n",
        "]\n",
        "categorical = [\n",
        "    \"fuelcooking\", \"sourcelighting\", \"watersource\", \"Toiletfacility\",\n",
        "    \"materialroof\", \"materialfloor\", \"materialwallsext\",\n",
        "    *[f\"HHMschoolcompl_{n}\" for n in range(1, 6)],\n",
        "    \"schoolcompleted\", \"livestocknumbers_1\",\n",
        "    *[f\"livestocknumbers_{i}\" for i in [1, 13, 3, 4, 5, 6, 11, 8, 9, 7, 2, 10]],\n",
        "    \"occupationmain\"\n",
        "]\n",
        "binary = [\n",
        "    \"childmortality\",\n",
        "    *[f\"foodsecurity{i}\" for i in range(1, 10)],\n",
        "    *[f\"HHMschool_{n}\" for n in range(1, 6)],\n",
        "    *[f\"HHMschoolnow_{n}\" for n in range(1, 6)],\n",
        "    \"school\", \"debt\", \"jealousy\",\n",
        "    \"assetsmatrix1_4\", \"assetsmatrix1_5\", \"assetsmatrix1_22\",\n",
        "    \"assetsmatrix2_15\", \"assetsmatrix2_8\", \"assetsmatrix3_17\",\n",
        "    \"assetsmatrix2_17\", \"assetsmatrix2_18\", \"assetsmatrix2_19\",\n",
        "    \"assetsmatrix2_11\", \"assetsmatrix3_15\", \"assetsmatrix3_23\",\n",
        "    \"meetings1\", \"moneywithdraw\", \"moneyproblems\"\n",
        "]\n",
        "multiple_choice = [\"debtnote\", \"jealousywhat\"]\n",
        "information = [\"Country\", \"Groupnr\", \"Round\"]\n",
        "\n",
        "\n",
        "# --- Benchmark Calculation Function (As Provided) ---\n",
        "def calculate_benchmarks(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Calculates benchmark statistics (mean/proportion) for all variables per round.\"\"\"\n",
        "    round_to_benchmark_map = {0: \"benchmark_baseline\", 1: \"benchmark_phone_survey_1\", 2: \"benchmark_phone_survey_2\",\n",
        "                              3: \"benchmark_phone_survey_3\", 100: \"benchmark_endline\",\n",
        "                              102: \"benchmark_post-program_survey_2\"}\n",
        "    binary_neg = [\"debt\", *[f\"foodsecurity{i}\" for i in range(1, 10)], \"childmortality\", \"jealousy\", \"assetsmatrix1_4\",\n",
        "                  \"assetsmatrix1_5\", \"assetsmatrix1_22\", \"assetsmatrix2_15\", \"assetsmatrix2_8\", \"assetsmatrix3_17\",\n",
        "                  \"assetsmatrix2_17\", \"assetsmatrix2_18\", \"assetsmatrix2_19\", \"assetsmatrix2_11\", \"assetsmatrix3_15\",\n",
        "                  \"assetsmatrix3_23\"]\n",
        "    binary_pos = [*[f\"HHMschoolnow_{n}\" for n in range(1, 6)], \"school\", \"meetings1\", \"moneywithdraw\", \"moneyproblems\"]\n",
        "\n",
        "    df_work = df.copy()\n",
        "    df_work['Round'] = pd.to_numeric(df_work['Round'], errors='coerce')\n",
        "    df_work.dropna(subset=['Round'], inplace=True)\n",
        "    df_work['Round'] = df_work['Round'].astype(int)\n",
        "    df_work = df_work[df_work['Round'].isin(round_to_benchmark_map.keys())]\n",
        "\n",
        "    all_benchmark_cols = list(set(numerical + ordered_categorical + binary))\n",
        "    for col in all_benchmark_cols:\n",
        "        if col in df_work.columns: df_work[col] = pd.to_numeric(df_work[col], errors='coerce')\n",
        "\n",
        "    agg_dict = {}\n",
        "    for col in list(set(numerical + ordered_categorical)):\n",
        "        if col in df_work.columns: agg_dict[col] = 'mean'\n",
        "    for col in binary_pos:\n",
        "        if col in df_work.columns: agg_dict[col] = lambda s: (s == 1).sum() / s.isin(\n",
        "            [1, 2]).sum() if s.isin([1, 2]).sum() > 0 else np.nan\n",
        "    for col in binary_neg:\n",
        "        if col in df_work.columns: agg_dict[col] = lambda s: (s == 2).sum() / s.isin(\n",
        "            [1, 2]).sum() if s.isin([1, 2]).sum() > 0 else np.nan\n",
        "\n",
        "    benchmarks_df = df_work.groupby('Round').agg(agg_dict)\n",
        "    benchmarks_df = benchmarks_df.rename(index=round_to_benchmark_map)\n",
        "\n",
        "    ordered_cols = [c for c in numerical + ordered_categorical + binary_pos + binary_neg if c in benchmarks_df.columns]\n",
        "    return benchmarks_df[ordered_cols]\n",
        "\n",
        "\n",
        "# --- Plotting & Data Prep Functions (Unchanged) ---\n",
        "def plot_groups_vs_overall(df, groups, variables, dpi=120):\n",
        "    round_order = [0, 1, 2, 3, 100, 102]\n",
        "    labels = {0: 'Baseline', 1: 'Phone survey 1', 2: 'Phone survey 2', 3: 'Phone survey 3', 100: 'Endline',\n",
        "              102: 'Post-program survey'}\n",
        "    df = df.copy();\n",
        "    df['Round'] = df['Round'].astype(int)\n",
        "    plt.style.use('ggplot');\n",
        "    cmap = plt.colormaps['tab10']\n",
        "    buffers = {}\n",
        "    for var in variables:\n",
        "        if var not in df.columns or df[var].dropna().empty: continue\n",
        "        fig, ax = plt.subplots(figsize=(10, 6), dpi=dpi)\n",
        "        overall_stats = df.groupby('Round')[var].agg(mean='mean', q1=lambda x: x.quantile(0.25),\n",
        "                                                     q3=lambda x: x.quantile(0.75)).reindex(round_order).reset_index()\n",
        "        overall_stats['lbl'] = overall_stats['Round'].map(labels)\n",
        "        overall_stats['iqr'] = overall_stats['q3'] - overall_stats['q1']\n",
        "        overall_stats['lower_bound'] = overall_stats['q1'] - 1.5 * overall_stats['iqr']\n",
        "        overall_stats['upper_bound'] = overall_stats['q3'] + 1.5 * overall_stats['iqr']\n",
        "        x_positions = np.arange(len(round_order))\n",
        "        ax.fill_between(x_positions, overall_stats['lower_bound'], overall_stats['upper_bound'], color='lightgray',\n",
        "                        alpha=0.6, label='Overall IQR ±1.5')\n",
        "        ax.plot(x_positions, overall_stats['lower_bound'], 'k-', lw=0.8);\n",
        "        ax.plot(x_positions, overall_stats['upper_bound'], 'k-', lw=0.8)\n",
        "        ax.plot(x_positions, overall_stats['mean'], linestyle='--', marker='o', color='tab:red', linewidth=2,\n",
        "                markersize=8, label='Overall average')\n",
        "        for i, grp in enumerate(groups):\n",
        "            sub = df[df['Groupnr'] == grp][['Round', var]].dropna()\n",
        "            if sub.empty: continue\n",
        "            pts = sorted(zip(sub['Round'], sub[var]), key=lambda x: round_order.index(x[0]))\n",
        "            rounds, vals = zip(*pts)\n",
        "            x_group_positions = [round_order.index(r) for r in rounds]\n",
        "            for j in range(1, len(rounds)):\n",
        "                idx0, idx1 = round_order.index(rounds[j - 1]), round_order.index(rounds[j])\n",
        "                style = '-' if idx1 - idx0 == 1 else 'dotted'\n",
        "                ax.plot(x_positions[[idx0, idx1]], [vals[j - 1], vals[j]], linestyle=style, color=cmap(i),\n",
        "                        linewidth=1.5)\n",
        "            ax.scatter(x_group_positions, vals, marker='s', s=50, color=cmap(i), label=f'Group {grp}')\n",
        "        ax.set_title(f'{var} trend for groups vs overall (with IQR band)', fontsize=16, pad=12)\n",
        "        ax.set_xlabel('Survey Round', fontsize=14, labelpad=8);\n",
        "        ax.set_ylabel(var, fontsize=14, labelpad=8)\n",
        "        ax.set_xticks(x_positions);\n",
        "        ax.set_xticklabels([labels[r] for r in round_order], rotation=45, ha='right')\n",
        "        ax.grid(alpha=0.3);\n",
        "        ax.spines['top'].set_visible(False);\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1));\n",
        "        plt.tight_layout()\n",
        "        buf = io.BytesIO();\n",
        "        fig.savefig(buf, format='png', bbox_inches='tight');\n",
        "        plt.close(fig);\n",
        "        buf.seek(0)\n",
        "        buffers[var] = buf\n",
        "    return buffers\n",
        "\n",
        "def growth_plot_raw_iqr(\n",
        "    df: pd.DataFrame,\n",
        "    grp: str,\n",
        "    var: str\n",
        ") -> io.BytesIO:\n",
        "    \"\"\"\n",
        "    Plot raw Δ growth vs. raw‐data IQR band.\n",
        "    \"\"\"\n",
        "    round_order = [0,1,2,3,100,102]\n",
        "    labels = {\n",
        "      0: 'Baseline', 1: 'Phone survey 1', 2: 'Phone survey 2',\n",
        "      3: 'Phone survey 3', 100: 'Endline', 102: 'Post-program survey'\n",
        "    }\n",
        "    raw_gc = f\"{var}_growth\"\n",
        "    if raw_gc not in df.columns:\n",
        "        return None\n",
        "\n",
        "    # 1) compute the raw IQR band on the raw growth column\n",
        "    stats = (\n",
        "      df.groupby('Round')[raw_gc]\n",
        "        .agg(Q1=lambda s: s.quantile(0.25),\n",
        "             Q3=lambda s: s.quantile(0.75))\n",
        "        .reindex(round_order)\n",
        "    )\n",
        "    iqr   = stats['Q3'] - stats['Q1']\n",
        "    lower = stats['Q1'] - 1.5*iqr\n",
        "    upper = stats['Q3'] + 1.5*iqr\n",
        "\n",
        "    # 2) compute the overall mean growth\n",
        "    avg = df.groupby('Round')[raw_gc].mean().reindex(round_order)\n",
        "\n",
        "    # 3) extract this one group’s raw growth\n",
        "    grp_ser = (\n",
        "      df[df['Groupnr']==grp]\n",
        "        .set_index('Round')[raw_gc]\n",
        "        .reindex(round_order)\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    x    = np.arange(len(round_order))\n",
        "    xlabs = [labels[r] for r in round_order]\n",
        "\n",
        "    plt.style.use('ggplot')\n",
        "    fig, ax = plt.subplots(figsize=(8,5), dpi=120)\n",
        "\n",
        "    # draw the raw IQR band\n",
        "    ax.fill_between(x, lower, upper, color='lightgray', alpha=0.6, label='Raw IQR ±1.5')\n",
        "    ax.plot(x, lower, 'k-', lw=1)\n",
        "    ax.plot(x, upper, 'k-', lw=1)\n",
        "\n",
        "    # draw the overall mean\n",
        "    ax.plot(x, avg.values, 'o--', c='tab:red', lw=2, ms=6, label='Avg growth')\n",
        "\n",
        "    # draw the group’s trajectory\n",
        "    ax.plot(x, grp_ser.values, 's-', c='tab:blue', lw=1.5, ms=6, label=f'Group {grp}')\n",
        "\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(xlabs, rotation=45, ha='right')\n",
        "    ax.set_title(f\"Raw‐data IQR on {var}_growth\", pad=12)\n",
        "    ax.set_ylabel(raw_gc)\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1.02,1))\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format='png', bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "    buf.seek(0)\n",
        "    return buf\n",
        "\n",
        "\n",
        "def growth_plot(df: pd.DataFrame, groups: list[str], var: str, window: int = 3) -> io.BytesIO:\n",
        "    round_order = [0, 1, 2, 3, 100, 102]\n",
        "    labels = {0: 'Baseline', 1: 'Phone survey 1', 2: 'Phone survey 2', 3: 'Phone survey 3', 100: 'Endline',\n",
        "              102: 'Post-program survey'}\n",
        "    x = np.arange(len(round_order));\n",
        "    xlabs = [labels[r] for r in round_order]\n",
        "    ewma_col = f\"{var}_EWMA_{window}_growth\"\n",
        "    if ewma_col not in df.columns: return None\n",
        "    stats = df.groupby('Round')[ewma_col].agg(Q1=lambda x: x.quantile(0.25), Q3=lambda x: x.quantile(0.75)).reindex(\n",
        "        round_order)\n",
        "    iqr = stats['Q3'] - stats['Q1']\n",
        "    lower = stats['Q1'] - 1.5 * iqr;\n",
        "    upper = stats['Q3'] + 1.5 * iqr\n",
        "    raw_gc = f\"{var}_growth\"\n",
        "    overall = df.groupby('Round')[raw_gc].mean().reindex(round_order)\n",
        "    plt.style.use('ggplot');\n",
        "    fig, ax = plt.subplots(figsize=(10, 5), dpi=120)\n",
        "    ax.fill_between(x, lower, upper, color='lightgray', alpha=0.6, label='EWMA IQR ±1.5')\n",
        "    ax.plot(x, lower, 'k-', lw=1);\n",
        "    ax.plot(x, upper, 'k-', lw=1)\n",
        "    ax.plot(x, overall.values, 'o--', color='red', lw=2, ms=6, label='Avg growth')\n",
        "    cmap = plt.get_cmap('tab10')\n",
        "    for i, gid in enumerate(groups): ax.plot([], [], color=cmap(i % 10), marker='s', linestyle='-', linewidth=1.5,\n",
        "                                             label=f\"Group {gid}\")\n",
        "\n",
        "    def plot_group(df_group, color):\n",
        "        y = (df_group.set_index('Round')[raw_gc].reindex(round_order).values)\n",
        "        valid_indices = ~np.isnan(y)\n",
        "        x_valid, y_valid = x[valid_indices], y[valid_indices]\n",
        "        for j in range(1, len(round_order)):\n",
        "            round0, round1, val0, val1 = round_order[j - 1], round_order[j], y[j - 1], y[j]\n",
        "            if not pd.isna(val0) and not pd.isna(val1):\n",
        "                idx0, idx1 = j - 1, j\n",
        "                style = '-'\n",
        "                ax.plot(x[[idx0, idx1]], y[[idx0, idx1]], color=color, lw=1.5, linestyle=style)\n",
        "        ax.scatter(x_valid, y_valid, color=color, s=60, marker='s')\n",
        "\n",
        "    for i, gid in enumerate(groups):\n",
        "        df_group = df[df['Groupnr'] == gid].copy()\n",
        "        if not df_group.empty and raw_gc in df_group.columns: plot_group(df_group, cmap(i % 10))\n",
        "    ax.set_xticks(x);\n",
        "    ax.set_xticklabels(xlabs, rotation=45, ha='right')\n",
        "    ax.set_ylabel(f\"{var}_growth (Δ)\");\n",
        "    ax.set_title(f\"Growth outliers: {var}\")\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1));\n",
        "    plt.tight_layout()\n",
        "    buf = io.BytesIO();\n",
        "    fig.savefig(buf, format='png', bbox_inches='tight');\n",
        "    plt.close(fig);\n",
        "    buf.seek(0)\n",
        "    return buf\n",
        "\n",
        "\n",
        "def add_ewma_columns(df: pd.DataFrame, variables: list[str] | None = None, span: int = 3, adjust: bool = True,\n",
        "                     min_periods: int = 1) -> pd.DataFrame:\n",
        "    df_ewma = df.copy()\n",
        "    if variables is None: variables = [col for col in df_ewma.select_dtypes(include='number').columns.tolist() if\n",
        "                                       col != 'Round']\n",
        "    for var in variables: df_ewma[f\"{var}_EWMA_{span}\"] = df_ewma.groupby('Groupnr')[var].transform(\n",
        "        lambda s: s.ewm(span=span, adjust=adjust, min_periods=min_periods).mean())\n",
        "    return df_ewma\n",
        "\n",
        "\n",
        "def add_growth_to_smoothed_with_interpolation(df: pd.DataFrame, col: str, group_key: str = 'Groupnr') -> pd.Series:\n",
        "    interp = df.groupby(group_key)[col].transform(lambda s: s.interpolate(method='linear', limit_area=None, limit=2))\n",
        "    return interp.groupby(df[group_key]).diff()\n",
        "\n",
        "\n",
        "def df_prep(df: pd.DataFrame, variables: list[str]) -> pd.DataFrame:\n",
        "    required_cols = ['Groupnr', 'Country', 'Round'] + variables\n",
        "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        variables = [col for col in variables if col not in missing_cols]\n",
        "        required_cols = ['Groupnr', 'Country', 'Round'] + variables\n",
        "    df2 = df[required_cols].copy()\n",
        "    df2 = df2[~df2['Round'].isin(['Onboarding', '6', '6.0']) & df2['Round'].notna()]\n",
        "    df2['Round'] = pd.to_numeric(df2['Round'], errors='coerce')\n",
        "    df2 = df2[df2['Round'] % 1 == 0];\n",
        "    df2['Round'] = df2['Round'].astype(int)\n",
        "    df2 = df2[df2['Round'].isin([0, 1, 2, 3, 100, 102])].sort_values('Round').reset_index(drop=True)\n",
        "    numeric_like_vars = list(\n",
        "        dict.fromkeys([v for v in variables if v not in ['Groupnr', 'Country', 'Round', 'livestocknumbers_1']]))\n",
        "    for col in numeric_like_vars:\n",
        "        if col in df2.columns: df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
        "    df_tr = df2.groupby(['Groupnr', 'Round'])[numeric_like_vars].mean().reset_index().sort_values(\n",
        "        ['Groupnr', 'Round']).reset_index(drop=True).copy()\n",
        "    df_tr = add_ewma_columns(df_tr, variables=numeric_like_vars, span=3, min_periods=1)\n",
        "    new_cols_data = {}\n",
        "    for var in numeric_like_vars:\n",
        "        col = f'{var}_EWMA_3'\n",
        "        if col in df_tr.columns: new_cols_data[f'{col}_growth'] = add_growth_to_smoothed_with_interpolation(df_tr, col)\n",
        "    for var in numeric_like_vars:\n",
        "        # new_cols_data[f'{var}_growth'] = df_tr.groupby('Groupnr')[var].diff()\n",
        "        interp_raw = df_tr.groupby('Groupnr')[var].transform(lambda s: s.interpolate(method='linear', limit_area=None, limit=2))\n",
        "\n",
        "        new_cols_data[f'{var}_growth'] = interp_raw.groupby(df_tr['Groupnr']).diff()\n",
        "        if var in df_tr.columns: new_cols_data[f'{var}_pct_growth'] = df_tr.groupby('Groupnr')[var].pct_change(\n",
        "            fill_method=None) * 100\n",
        "    if new_cols_data: df_tr = pd.concat([df_tr, pd.DataFrame(new_cols_data, index=df_tr.index)], axis=1)\n",
        "    df_tr = df_tr.sort_values(['Groupnr', 'Round']).reset_index(drop=True)\n",
        "    return df_tr\n",
        "\n",
        "\n",
        "def final_prep(raw_df, variables, groups, country, window=3):\n",
        "    df_all = df_prep(raw_df, variables)\n",
        "    df_all = df_all.drop_duplicates(subset=['Groupnr', 'Round'])\n",
        "    if country: df_all = df_all[df_all['Groupnr'].str.startswith(country)]\n",
        "    iqr_bands, avg_growth = {}, {}\n",
        "    for var in variables:\n",
        "        raw_gc, ewma_gc = f\"{var}_growth\", f\"{var}_EWMA_{window}_growth\"\n",
        "        if ewma_gc not in df_all.columns or raw_gc not in df_all.columns: continue\n",
        "        if df_all[ewma_gc].dropna().empty:\n",
        "            lower, upper = pd.Series(np.nan), pd.Series(np.nan)\n",
        "        else:\n",
        "            q1_ewma, q3_ewma = df_all.groupby('Round')[ewma_gc].quantile(0.25), df_all.groupby('Round')[\n",
        "                ewma_gc].quantile(0.75)\n",
        "            iqr_ewma = q3_ewma - q1_ewma\n",
        "            lower, upper = q1_ewma - 1.5 * iqr_ewma, q3_ewma + 1.5 * iqr_ewma\n",
        "        iqr_bands[var] = pd.DataFrame({'lower': lower, 'upper': upper})\n",
        "        if df_all[raw_gc].dropna().empty:\n",
        "            avg_growth[var] = pd.Series(np.nan)\n",
        "        else:\n",
        "            avg_growth[var] = df_all.groupby('Round')[raw_gc].mean()\n",
        "    df_filt = df_all[df_all['Groupnr'].isin(groups)]\n",
        "    flags = {var: {} for var in variables}\n",
        "    for var in variables:\n",
        "        if var not in iqr_bands or var not in avg_growth: continue\n",
        "        band = iqr_bands[var].reset_index().rename(columns={'index': 'Round'})\n",
        "        raw_gc = f\"{var}_growth\"\n",
        "        if raw_gc not in df_filt.columns: continue\n",
        "        tmp = df_filt[['Groupnr', 'Round', raw_gc]].merge(band, on='Round', how='left')\n",
        "        for _, r in tmp.iterrows():\n",
        "            v = r[raw_gc]\n",
        "            if pd.isna(v) or pd.isna(r['lower']) or pd.isna(r['upper']): continue\n",
        "            if v < r['lower']:\n",
        "                flags[var][(r['Groupnr'], r['Round'])] = 'NEG'\n",
        "            elif v > r['upper']:\n",
        "                flags[var][(r['Groupnr'], r['Round'])] = 'POS'\n",
        "    rows = [{'Groupnr': grp, 'Round': rnd, 'variable': var, 'flag': tag} for var, vf in flags.items() for\n",
        "            (grp, rnd), tag in vf.items()]\n",
        "    df_flags = pd.DataFrame(rows)\n",
        "    if not df_flags.empty:\n",
        "        df_out = df_flags.pivot(index=['Groupnr', 'Round'], columns='variable', values='flag').reset_index()\n",
        "    else:\n",
        "        df_out = pd.DataFrame(columns=['Groupnr', 'Round'] + variables)\n",
        "    return df_out, flags, df_all\n",
        "\n",
        "\n",
        "# --- NEW: Function to calculate outliers based on static values within a round ---\n",
        "def calculate_round_outliers(df: pd.DataFrame, num_bin_vars: list[str], cat_vars: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates outliers based on static values within each round using the IQR method.\n",
        "    - For numerical/binary variables, it uses the group's mean.\n",
        "    - For categorical variables, it uses the percentage for each category.\n",
        "    \"\"\"\n",
        "    all_outliers = []\n",
        "    df_work = df.copy()\n",
        "    df_work['Round'] = pd.to_numeric(df_work['Round'], errors='coerce').astype('Int64')\n",
        "\n",
        "    # Ensure relevant columns are numeric\n",
        "    for col in num_bin_vars:\n",
        "        if col in df_work.columns:\n",
        "            df_work[col] = pd.to_numeric(df_work[col], errors='coerce')\n",
        "\n",
        "    rounds = sorted(df_work['Round'].dropna().unique())\n",
        "\n",
        "    # --- Part 1: Numerical and Binary Variables ---\n",
        "    for var in num_bin_vars:\n",
        "        if var not in df_work.columns: continue\n",
        "\n",
        "        # Calculate group means for the variable across all rounds\n",
        "        group_means = df_work.groupby(['Round', 'Groupnr'])[var].mean().reset_index()\n",
        "\n",
        "        for r in rounds:\n",
        "            round_means = group_means[group_means['Round'] == r][var]\n",
        "            if len(round_means) < 4: continue  # Not enough data for IQR\n",
        "\n",
        "            Q1 = round_means.quantile(0.25)\n",
        "            Q3 = round_means.quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            if IQR == 0: continue\n",
        "\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "            outliers = group_means[\n",
        "                (group_means['Round'] == r) &\n",
        "                ((group_means[var] < lower_bound) | (group_means[var] > upper_bound))\n",
        "                ]\n",
        "\n",
        "            for _, row in outliers.iterrows():\n",
        "                flag = \"HIGH\" if row[var] > Q3 else \"LOW\"\n",
        "                description = f\"{var} ({flag} mean: {row[var]:.2f})\"\n",
        "                all_outliers.append({\n",
        "                    'Groupnr': row['Groupnr'], 'Round': r, 'flag_description': description\n",
        "                })\n",
        "\n",
        "    # --- Part 2: Categorical Variables ---\n",
        "    for var in cat_vars:\n",
        "        if var not in df_work.columns or df_work[var].nunique() < 2: continue\n",
        "\n",
        "        for r in rounds:\n",
        "            df_round = df_work[df_work['Round'] == r].dropna(subset=[var])\n",
        "            if df_round.empty: continue\n",
        "\n",
        "            # Calculate percentage of each category per group\n",
        "            cross_tab = pd.crosstab(index=df_round['Groupnr'], columns=df_round[var], normalize='index') * 100\n",
        "            if cross_tab.shape[0] < 4: continue\n",
        "\n",
        "            # Check each category for outliers\n",
        "            for category in cross_tab.columns:\n",
        "                cat_percentages = cross_tab[category]\n",
        "\n",
        "                Q1 = cat_percentages.quantile(0.25)\n",
        "                Q3 = cat_percentages.quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                if IQR == 0: continue\n",
        "\n",
        "                # We are primarily interested in unusually high percentages\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "                outliers = cat_percentages[cat_percentages > upper_bound]\n",
        "\n",
        "                for group, pct_val in outliers.items():\n",
        "                    description = f\"{var}: {category} (HIGH %: {pct_val:.0f}%)\"\n",
        "                    all_outliers.append({\n",
        "                        'Groupnr': group, 'Round': r, 'flag_description': description\n",
        "                    })\n",
        "\n",
        "    if not all_outliers:\n",
        "        return pd.DataFrame()\n",
        "    return pd.DataFrame(all_outliers)\n",
        "\n",
        "\n",
        "# --- FINALIZED: xlsx file generator with clustering instructions ---\n",
        "def xlsx_generator(raw_df, variables, country, groups, window=3):\n",
        "    print(\"Step 1: Preparing data and identifying trend outliers...\")\n",
        "    all_vars = variables\n",
        "\n",
        "    vars_to_exclude = (\n",
        "    [f\"foodsecurity{i}freq\" for i in range(1, 10)] +\n",
        "    [f\"foodsecurity{i}\" for i in range(1, 10)] +\n",
        "    [f\"livestocknumbers_{i}\" for i in [1, 13, 3, 4, 5, 6, 11, 8, 9, 7, 2, 10]] +\n",
        "    [f\"HHMschool_{n}\" for n in range(1, 6)] +\n",
        "    [f\"HHMschoolnow_{n}\" for n in range(1, 6)] +\n",
        "    [f\"HHMschoolcompl_{n}\" for n in range(1, 6)] +\n",
        "    [\"assetsmatrix1_4\", \"assetsmatrix1_5\", \"assetsmatrix1_22\",\n",
        "    \"assetsmatrix2_15\", \"assetsmatrix2_8\", \"assetsmatrix3_17\",\n",
        "    \"assetsmatrix2_17\", \"assetsmatrix2_18\", \"assetsmatrix2_19\",\n",
        "    \"assetsmatrix2_11\", \"assetsmatrix3_15\", \"assetsmatrix3_23\"]\n",
        "    )\n",
        "\n",
        "\n",
        "    trend_vars = [var for var in all_variables if var not in vars_to_exclude]\n",
        "\n",
        "    _, flags, df_all = final_prep(raw_df, trend_vars, groups, country, window)\n",
        "\n",
        "    print(\"Step 2: Calculating benchmark statistics...\")\n",
        "    country_df = raw_df[raw_df['Country'] == country].copy()\n",
        "    df_benchmarks = calculate_benchmarks(country_df)\n",
        "\n",
        "    print(\"Step 2b: Calculating round-based outliers...\")\n",
        "\n",
        "    num_bin_vars_for_calc = list(set(numerical + binary))\n",
        "\n",
        "    num_bin_vars_for_calc = [v for v in num_bin_vars_for_calc if v in country_df.columns]\n",
        "\n",
        "    cat_vars_for_calc = [v for v in categorical if v in country_df.columns]\n",
        "\n",
        "\n",
        "    df_round_outliers = calculate_round_outliers(country_df, num_bin_vars_for_calc, cat_vars_for_calc)\n",
        "\n",
        "    # --- Setup Excel Writer ---\n",
        "    filename = f\"Trend_analysis (raw data based outlier detection) by Group for {country}.xlsx\"\n",
        "    writer = pd.ExcelWriter(filename, engine=\"xlsxwriter\")\n",
        "    workbook = writer.book\n",
        "    bold = workbook.add_format({\"bold\": True})\n",
        "    plot_title_format = workbook.add_format({'bold': True, 'font_size': 11})\n",
        "    wrap_format = workbook.add_format({'text_wrap': True, 'valign': 'top'})\n",
        "    url_format = workbook.add_format({'font_color': 'blue', 'underline': 1})\n",
        "\n",
        "    # --- Writing Summary Sheets ---\n",
        "    print(\"Step 3: Writing summary sheets to Excel...\")\n",
        "\n",
        "    # --- REVISED: Add the Clustering sheet with the hyperlink and instructions ---\n",
        "    clustering_ws = workbook.add_worksheet(\"clustering\")\n",
        "\n",
        "    # Define your instructional text here. You can paste your final text inside the triple quotes.\n",
        "    instructional_text = \"\"\"Instructions for the Clustering Application :\n",
        "\n",
        "Introduction\n",
        "This application was developed for 100WEEKS to compare the performance of participating groups\n",
        "of women during the program. With the application, vulnerable groups can be identified and\n",
        "additional support can be provided.\n",
        "\n",
        "Access to the Application\n",
        "https://100weeks-clustering.streamlit.app/\n",
        "The application is developed to be user-friendly and it does not require any technical background to\n",
        "operate. After opening the application, a specific country can be selected via the drop-down menu.\n",
        "Based on this selection, visualizations are generated for the different survey rounds within that\n",
        "country. Plots are visualized for the baseline, round 2 (after 50 weeks), and round 100 (after 100\n",
        "weeks).\n",
        "\n",
        "Using the Application\n",
        "Every plot shows the results of a specific survey round. Each data point in the plot represents a\n",
        "participating group of women in the 100WEEKS program. By moving the computer mouse over a\n",
        "data point, the corresponding group number is displayed. In addition, a search bar is included for each\n",
        "plot where you can manually search for a specific group (e.g. GHA001). The group will appear in the\n",
        "plot, marked with a cross. The bottom left corner of the plots usually contains the most vulnerable\n",
        "groups, which score relatively low on poverty-related indicators. The top right corner shows groups\n",
        "that do relatively well on these indicators. It is important to mention that the plots are based on a\n",
        "simplified representation of the data. The dataset with multiple dimensions is reduced to two principal\n",
        "dimensions using Principal Component Analysis (PCA). This ensures that the results can be\n",
        "visualized in two-dimensional plots, but the plots only show an approximation of reality.\n",
        "\n",
        "Technical Setup\n",
        "The complete code and dataset are stored in the following GitHub repository:\n",
        "https://github.com/sam-jager/100weeks-clustering. The clustering.py file contains all of the python\n",
        "code. The file requirements.txt contains the Python libraries that are needed for the application to run.\n",
        "\n",
        "Adding a New Dataset\n",
        "When a new dataset is available for analysis, this can be uploaded with these steps. First, click the link\n",
        "to open the 100weeks-clustering GitHub repository. Click on the button ‘Add file’ and upload the new\n",
        "dataset. After this, open the clustering.py file and search for the following line of code at the\n",
        "beginning of the file:\n",
        "url = \"https://raw.githubusercontent.com/sam-jager/100weeks-clustering/main/central-tableau-export-2.0.csv\".\n",
        "Replace the filename (central-tableau-export-2.0.csv) in this URL with the new dataset’s filename.\n",
        "Save the changes with the ‘Commit changes’ button. The application automatically uses the new\n",
        "dataset.\n",
        "\"\"\"\n",
        "\n",
        "    # Set column width to be wide enough for instructions\n",
        "    clustering_ws.set_column('A:A', 80)\n",
        "\n",
        "    # Write the hyperlink to cell A1\n",
        "    clustering_ws.write_url(\n",
        "        'A1',\n",
        "        'https://100weeks-clustering.streamlit.app/',\n",
        "        url_format,\n",
        "        'Link to the Clustering Application'\n",
        "    )\n",
        "\n",
        "    # Write the instructional text to cell A3, applying the wrap format\n",
        "    clustering_ws.write('A3', instructional_text, wrap_format)\n",
        "\n",
        "    # Sheet: Trend-based Outlier Summary\n",
        "    summary_ws = workbook.add_worksheet(\"growth_outlier_summary\")\n",
        "    all_flags_rows = [\n",
        "        {'Groupnr': g, 'variable': var, 'Round': rnd}\n",
        "        for var, vf in flags.items()\n",
        "        for (g, rnd), tag in vf.items()\n",
        "    ]\n",
        "    if not all_flags_rows:\n",
        "        summary_ws.write('A1', 'No trend-based outliers found to summarize.')\n",
        "    else:\n",
        "        df_flags_long = pd.DataFrame(all_flags_rows)\n",
        "        df_grouped = (\n",
        "            df_flags_long.groupby(['Groupnr', 'Round'])['variable']\n",
        "            .apply(lambda x: '\\n'.join(sorted(x)))\n",
        "            .reset_index()\n",
        "        )\n",
        "        df_outlier_summary = df_grouped.pivot(\n",
        "            index='Groupnr', columns='Round', values='variable'\n",
        "        )\n",
        "        desired_round_order = [0, 1, 2, 3, 100, 102]\n",
        "        df_outlier_summary = df_outlier_summary.reindex(columns=desired_round_order).fillna('').reset_index()\n",
        "        summary_ws.set_column('A:A', 15);\n",
        "        summary_ws.set_column('B:G', 30)\n",
        "        for col_num, value in enumerate(df_outlier_summary.columns.values):\n",
        "            summary_ws.write(0, col_num, value, bold)\n",
        "        for row_num, row_data in enumerate(df_outlier_summary.itertuples(index=False), start=1):\n",
        "            summary_ws.write(row_num, 0, row_data[0])\n",
        "            for col_num, cell_data in enumerate(row_data[1:], start=1):\n",
        "                summary_ws.write(row_num, col_num, cell_data, wrap_format)\n",
        "\n",
        "    # Sheet: Round-based Outlier Summary\n",
        "    round_summary_ws = workbook.add_worksheet(\"round_outlier_summary\")\n",
        "    if df_round_outliers.empty:\n",
        "        round_summary_ws.write('A1', 'No round-based outliers found to summarize.')\n",
        "        print(\"No round-based outliers found.\")\n",
        "    else:\n",
        "        df_round_grouped = (\n",
        "            df_round_outliers.groupby(['Groupnr', 'Round'])['flag_description']\n",
        "            .apply(lambda x: '\\n'.join(sorted(x)))\n",
        "            .reset_index()\n",
        "        )\n",
        "        df_round_pivot = df_round_grouped.pivot(\n",
        "            index='Groupnr', columns='Round', values='flag_description'\n",
        "        )\n",
        "        desired_round_order = [0, 1, 2, 3, 100, 102]\n",
        "        df_round_pivot = df_round_pivot.reindex(columns=desired_round_order).fillna('').reset_index()\n",
        "        round_summary_ws.set_column('A:A', 15);\n",
        "        round_summary_ws.set_column('B:G', 40)\n",
        "        for col_num, value in enumerate(df_round_pivot.columns.values):\n",
        "            round_summary_ws.write(0, col_num, value, bold)\n",
        "        for row_num, row_data in enumerate(df_round_pivot.itertuples(index=False), start=1):\n",
        "            round_summary_ws.write(row_num, 0, row_data[0])\n",
        "            for col_num, cell_data in enumerate(row_data[1:], start=1):\n",
        "                round_summary_ws.write(row_num, col_num, cell_data, wrap_format)\n",
        "\n",
        "    # Sheet: Benchmark Summary\n",
        "    df_benchmarks.to_excel(writer, sheet_name=\"benchmark_summary\", index=True)\n",
        "\n",
        "    # --- EXISTING: Write Per-Group Sheets (Based on trend outliers) ---\n",
        "    print(f\"Step 4: Generating individual sheets for flagged groups...\")\n",
        "    for grp in groups:\n",
        "        rows = [{\"Round\": rnd, \"variable\": var, \"flag\": tag} for var, vf in flags.items() for (g, rnd), tag in\n",
        "                vf.items() if g == grp]\n",
        "        if not rows: continue\n",
        "        df_grp = pd.DataFrame(rows)\n",
        "        df_wide = df_grp.pivot(index=\"Round\", columns=\"variable\", values=\"flag\").reset_index().replace(\n",
        "            [np.inf, -np.inf, np.nan], None)\n",
        "        ws = workbook.add_worksheet(grp)\n",
        "        for c, col in enumerate(df_wide.columns): ws.write(0, c, col, bold)\n",
        "        for r, rec in enumerate(df_wide.itertuples(index=False), start=1):\n",
        "            for c, val in enumerate(rec): ws.write(r, c, val)\n",
        "        rowpos = len(df_wide) + 2\n",
        "        vars_flagged = sorted(df_grp[\"variable\"].unique())\n",
        "    for var in vars_flagged:\n",
        "        ws.write(rowpos, 0, f\"Analysis for variable: {var}\", plot_title_format)\n",
        "        rowpos += 2\n",
        "\n",
        "        # A) Raw‐data IQR on raw growth\n",
        "        raw_img = growth_plot_raw_iqr(df_all, grp, var)\n",
        "        if raw_img:\n",
        "            ws.insert_image(rowpos, 0, \"\", {\"image_data\": raw_img, \"x_scale\": 0.75, \"y_scale\": 0.75})\n",
        "\n",
        "        rowpos += 22\n",
        "\n",
        "    writer.close()\n",
        "    print(f\"✅ Success! Workbook saved to {filename}\")\n",
        "\n",
        "all_variables = numerical + ordered_categorical + binary + categorical\n",
        "raw_df = df.copy()"
      ],
      "metadata": {
        "id": "lCeCdOe4Gjmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final choice"
      ],
      "metadata": {
        "id": "RO4Ed4s6Grnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a country and run the code, can take some time"
      ],
      "metadata": {
        "id": "9pu9Mi7FG6L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For country fill in either 'RWA', 'UGA', 'CIV', 'GHA', 'KEN'\n",
        "country = 'UGA'\n"
      ],
      "metadata": {
        "id": "I6aEIZ9VGu74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this afterwards"
      ],
      "metadata": {
        "id": "rkM06q_NKWXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groups = raw_df[raw_df['Country'] == country]['Groupnr'].unique().tolist()\n",
        "xlsx_generator(raw_df, country, groups, 3)"
      ],
      "metadata": {
        "id": "hX0YxCTCKa0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
